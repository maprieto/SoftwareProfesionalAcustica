{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software profesional en Acústica 2020-21 (M2i)\n",
    "\n",
    "*This notebook contains some excerpts with modifications from the W3Schools - Python course (available at https://www.w3schools.com/python/scipy_getting_started.asp and https://www.w3schools.com/python/scipy_matlab_arrays.asp) Copyright: 2021 W3Schools Courses All Rights Reserved, and also from the blog entry [Introduction to Sparse Matrices in Python with SciPy](https://cmdlinetips.com/2018/03/sparse-matrices-in-python-with-scipy/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scipy\n",
    "\n",
    "**SciPy** is a scientific computation library that uses NumPy underneath.SciPy stands for Scientific Python. It provides more utility functions for optimization, stats and signal processing. Like NumPy, SciPy is open source so we can use it freely. SciPy was created by NumPy's creator Travis Olliphant.\n",
    "\n",
    "**SciPy** has optimized and added functions that are frequently used in NumPy and Data Science. It is predominantly written in Python, but a few segments are written in C. The source code for SciPy is located at this github repository https://github.com/scipy/scipy.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Working with sparse matrices: storage and solving linear systems \n",
    "- Load and save Matlab .mat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse matrices\n",
    "\n",
    "What is a Sparse Matrix? Imagine you have a two-dimensional data set with 10 rows and 10 columns such that each element contains a value. We can also call such data as matrix, in this example it is a dense 10 x 10 matrix. Now imagine, you have a 10 x 10 matrix with only very few elements of the matrix is non-zero. In that case, storing the data in such a two dimensional data structure is waste of space. When the dimension of such data is large, it becomes almost impossible to use/store.\n",
    "\n",
    "<img src=\"images/Sparse_Matrix.png\" alt=\"Sparse Dense matrices\" title=\"Comparison of sparse and dense matrices.\" width=\"600\"/>\n",
    "\n",
    "### What is Sparse Matrix?\n",
    "Sparse matrices are memory efficient data structures that enable us store large matrices with very few non-zero elements aka sparse matrices. In addition to efficient storage, sparse matrix data structure also allows us to perform complex matrix computations. The ability to do such computations is incredibly powerful in a variety of data science problems. Learning to work with Sparse matrix, a large matrix or 2d-array with a lot elements being zero, can be extremely handy.\n",
    "\n",
    "Python's SciPy library has a lot of options for creating, storing, and operating with Sparse matrices. There are 7 different types of sparse matrices available.\n",
    "\n",
    "1. bsr_matrix: Block Sparse Row matrix\n",
    "2. coo_matrix: COOrdinate format matrix\n",
    "3. csc_matrix: Compressed Sparse Column matrix\n",
    "4. csr_matrix: Compressed Sparse Row matrix\n",
    "5. dia_matrix: Sparse matrix with DIAgonal storage\n",
    "6. dok_matrix: Dictionary Of Keys based sparse matrix.\n",
    "7. lil_matrix: Row-based linked list sparse matrix\n",
    "\n",
    "### How to Choose the Right Sparse Matrix?\n",
    "Each of these sparse matrix are efficient and fast for specific operations. For example, if you want to construct a new sparse matrix from scratch lil_matrix or dok_matrix are efficient. However, arithmetic operations on matrices are not efficient. coo_matrix has similar properties; good for creating sparse matrix, but bad for operations.\n",
    "\n",
    "If you are interested in matrix operations, like multiplication or inversion either CSC or CSR sparse matrix format is more suitable/efficient. Due to the nature of the data structure, csc_matrix has faster/efficient column slicing, while csr_matrix has faster row slicing.\n",
    "\n",
    "In this post, we will see a few simple examples of creating sparse matrix and using them in Python. Let us get started with loading the necessary packages/modules upfront. We will be using SciPy’s sparse module for the sparse matrices.\n",
    "\n",
    "Choosing the right sparse matrix depends on the application. Typically, you may have to use multiple sparse matrix formats to get the job done. SciPy’s sparse module has really nice functions to convert one sparse matrix type to another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sparse module from SciPy package \n",
    "from scipy import sparse\n",
    "# import uniform module to create random numbers\n",
    "from scipy.stats import uniform\n",
    "# import NumPy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Create COO sparse matrix?\n",
    "One of the more intuitive matrices is COOordinate sparse matrix. One can create COO sparse matrix fast. We basically need the co-ordinates of non-zero elements in the sparse matrix.\n",
    "\n",
    "To create a coo_matrix we need 3 one-dimensional numpy arrays. The first array represents the row indices, the second array represents column indices and the third array represents non-zero data in the element. The row and column indices specify the location of non-zero element and the data array specifies the actual non-zero data in it.\n",
    "\n",
    "Let us create a sparse matrix in COO format using simple example. Let us first create 3 numpy arrays needed to create COO sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row indices\n",
    "row_ind = np.array([0, 1, 1, 3, 4])\n",
    "# column indices\n",
    "col_ind = np.array([0, 2, 4, 3, 4])\n",
    "# data to be stored in COO sparse matrix\n",
    "data = np.array([1, 2, 3, 4, 5], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use sparse.coo_matrix to create sparse matrix in COO format. It takes data and the row and column index tuple as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 2)\t2.0\n",
      "  (1, 4)\t3.0\n",
      "  (3, 3)\t4.0\n",
      "  (4, 4)\t5.0\n"
     ]
    }
   ],
   "source": [
    "# create COO sparse matrix from three arrays\n",
    "mat_coo = sparse.coo_matrix((data, (row_ind, col_ind)))\n",
    "# print coo_matrix\n",
    "print(mat_coo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coo_matrix has lots of useful functions including function to convert coo_matrix to other sparse matrices and also to dense matrix. Here is a function toarray to see the 2d-array of the sparse matrix that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 2. 0. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 4. 0.]\n",
      " [0. 0. 0. 0. 5.]]\n"
     ]
    }
   ],
   "source": [
    "print(mat_coo.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Create DIA sparse matrix?\n",
    "One of the more intuitive matrices is the parse matrix with DIAgonal storage. One can create DIA sparse matrix fast. We basically need the diagonals (the coefficients of the super- and sub-diagonals of the matrix) and their respective index (position of the super- and sub-diagonals) with respect to the main diagonal (with index zero).\n",
    "\n",
    "For instance, a tridiagonal matrix with main diagonal $v_{1}$, sub-diagonal $v_{2}$ and super-diagonal $v_{3}$ can be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 10,  0,  0],\n",
       "       [ 5,  2, 11,  0],\n",
       "       [ 0,  6,  3, 12],\n",
       "       [ 0,  0,  7,  4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import spdiags\n",
    "v1 = np.array([1, 2, 3, 4])\n",
    "v2 = np.array([5, 6, 7, 8])\n",
    "v3 = np.array([9, 10, 11, 12])\n",
    "data = np.array([v1, v2, v3])\n",
    "diags = np.array([0, -1, 1])\n",
    "spdiags(data, diags, 4, 4).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much space do we gain by storing a big sparse matrix in SciPy.sparse?\n",
    "\n",
    "One of the real uses of sparse matrix is the huge space reduction to store sparse matrices. Let us create a bigger full matrix using uniform random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "data = uniform.rvs(size=1000000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (10000, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make the matrix sparse by making certain elements zero. As before, we make any element whose value is less than 1 to 0. We can use nbytes function in NumPy to get the number of bytes and get the size of the matrix in MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of full matrix with zeros: 7.63 MB\n"
     ]
    }
   ],
   "source": [
    "data[data < 1] = 0\n",
    "data_size = data.nbytes/(1024**2)\n",
    "print('Size of full matrix with zeros: '+ '%3.2f' %data_size + ' MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the size of full matrix of size 1 Million elements with half of them with values zero is about 8 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sparse coo_matrix: 0.48 MB\n"
     ]
    }
   ],
   "source": [
    "data_coo = sparse.coo_matrix(data)\n",
    "data_coo_size = data_coo.data.size/(1024**2)\n",
    "print('Size of sparse coo_matrix: '+ '%3.2f' %data_coo_size + ' MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the use of sparse matrix, the size of the data in the sparse matrix is just about 0.5MB, a huge reduction is space. This is mainly due efficient data structure to store only the non-zero elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve a sparse linear system \n",
    "We will review in the following Jupyter notebooks that it is essential to solve efficiently linear systems of equations associated with the Finite Difference discretizations or the Finite Element Method. In both cases, the associated discrete matrices will be sparse. During the solving procedure, it is required to preserve (as much as possible) the sparsity of the matrices without refilling the null entries innecesarelly. For that purpouse, the function ``spsolve`` is used. The only drawback of the use of ``spsolve`` consists in the system matrix must be stored in CSR or CSC format. Otherwise, it will be transformed into CSR format losing part of its efficiency.\n",
    "\n",
    "For instance, a tridiagonal matrix $M$ with diagonal coefficients equal to $2$, and sub- and super-diagonal coefficientes equal to $1$, represents the typical mass matrix in a second-order one-dimensional finite difference scheme. If the pointwise values of $f$ are stored in vector $\\vec{b}=(f(x_{1}),\\ldots,f(x_{N}))^T$, then the solution of the linear system $M\\vec{x}=\\vec{b}$ represents the pointwise values of the $L^2$-projection of the pointwise values of $f$ on the the finite difference grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import spsolve\n",
    "# Compute the right-hand side from f(x)=cos(x) in [0,1] with 100 points\n",
    "n=100\n",
    "b=np.cos(np.linspace(0,1,n))\n",
    "# Compute the mass matrix\n",
    "v=np.ones(n)\n",
    "data = np.array([2*v, v, v])\n",
    "diags = np.array([0, -1, 1])\n",
    "M = spdiags(data, diags, n, n)\n",
    "x = spsolve(M.tocsr(), b) # Transform matrix fo CSC format before being solved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Matlab Arrays\n",
    "We know that **NumPy** provides us with methods to persist the data in readable formats for Python. But **SciPy** provides us with interoperability with Matlab as well. **SciPy** provides us with the module ``scipy.io``, which has functions for working with **Matlab** arrays.\n",
    "\n",
    "### Exporting Data in Matlab Format\n",
    "The ``savemat()`` function allows us to export data in Matlab format. The method takes the following parameters:\n",
    "\n",
    "1. ``filename`` - the file name for saving data.\n",
    "2. ``mdict`` - a dictionary containing the data.\n",
    "3. ``do_compression`` - a boolean value that specifies wheter to compress the reult or not. Default ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "\n",
    "arr = np.arange(10)\n",
    "# Export vector arr\n",
    "io.savemat('results/arr.mat', {\"vec\": arr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: The example above saves a file name \"arr.mat\" on your computer.\n",
    "To open the file, check out the \"Import Data from Matlab Format\" example below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from Matlab Format\n",
    "The ``loadmat()`` function allows us to import data from a Matlab file. The function takes one required parameter:\n",
    "\n",
    "``filename`` - the file name of the saved data.\n",
    "\n",
    "It will return a structured array whose keys are the variable names, and the corresponding values are the variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Tue Apr  6 01:37:33 2021', '__version__': '1.0', '__globals__': [], 'vec': array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])}\n"
     ]
    }
   ],
   "source": [
    "# Import:\n",
    "mydata = io.loadmat('results/arr.mat')\n",
    "\n",
    "print(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Solve the linear system associated with the $L^2$-projection in a finite difference discretization with different grid sizes $n=10, 20, 40, 80, 160, 320$. Check the memory storage required to save the matrix in Python and the size of the .mat file. Is there any different both memory sizes? When the linear system is solved, does the computational time scale with the same ratio as the used memory size? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
